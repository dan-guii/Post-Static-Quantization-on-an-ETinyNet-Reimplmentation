{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kZF59tkfTGIh",
        "outputId": "bb802044-5983-49ce-d568-b7398781e00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "print(os.getcwd())\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.quantized as nnq\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "qP1v0eBUTWY7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformation and loading\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224, 224)), transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "calibration_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "calibration_subset = torch.utils.data.Subset(calibration_dataset, torch.randperm(len(calibration_dataset))[:1000])\n",
        "calibration_loader = DataLoader(calibration_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7NhC5PBt2XxB",
        "outputId": "c1116594-3f86-439f-a037-5bfbc13b9702"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 106MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LBBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super(LBBlock, self).__init__()\n",
        "        # First depthwise convolution (ϕ_d1) with batch normalization\n",
        "        self.depthwise1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, groups=in_channels)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "        # Pointwise convolution (ϕ_p) with batch normalization\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Second depthwise convolution (ϕ_d2) with batch normalization\n",
        "        self.depthwise2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding, groups=out_channels)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise1(x)                 # First depthwise convolution (ϕ_d1)\n",
        "        x = self.bn1(x)                        # Batch normalization after ϕ_d1\n",
        "        x = self.pointwise(x)                  # Pointwise convolution (ϕ_p)\n",
        "        x = self.bn2(x)                        # Batch normalization after ϕ_p\n",
        "        x = self.relu1(x)                          # ReLU after pointwise\n",
        "        x = self.depthwise2(x)                 # Second depthwise convolution (ϕ_d2)\n",
        "        x = self.bn3(x)                        # Batch normalization after ϕ_d2\n",
        "        x = self.relu2(x)                          # ReLU after second depthwise\n",
        "        return x\n",
        "\n",
        "class DLBBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super(DLBBlock, self).__init__()\n",
        "        if in_channels != out_channels:\n",
        "            self.match_channels = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        else:\n",
        "            self.match_channels = None\n",
        "\n",
        "        self.depthwise1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, groups=in_channels)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.depthwise2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding, groups=out_channels)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Add the FloatFunctional module for quantized addition\n",
        "        self.add = nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.match_channels(x) if self.match_channels else x\n",
        "\n",
        "        x = self.depthwise1(x)\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        # Use quantized addition\n",
        "        x = self.add.add(x, residual)\n",
        "        residual1 = x\n",
        "\n",
        "        x = self.depthwise2(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        # Use quantized addition for final shortcut connections\n",
        "        x = self.add.add(x, residual)\n",
        "        x = self.add.add(x, residual1)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "aWiv76J6TwX0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EtinyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EtinyNet, self).__init__()\n",
        "\n",
        "        # Initial 3x3 convolution with stride 2 to downsample\n",
        "        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # First pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # First set of LBBlocks: [32, 32, 32, 32] -> 56x56 feature map\n",
        "        self.lb1 = nn.Sequential(\n",
        "            LBBlock(32, 32),\n",
        "            LBBlock(32, 32),\n",
        "            LBBlock(32, 32),\n",
        "            LBBlock(32, 32)\n",
        "        )\n",
        "\n",
        "        # Second set of LBBlocks: [32, 128, 128, 128] -> 28x28 feature map\n",
        "        self.lb2 = nn.Sequential(\n",
        "            # First part: [32, 128, 128] x 1\n",
        "            LBBlock(32, 128),  # Expands channels from 32 to 128\n",
        "\n",
        "            # Second part: [128, 128, 128] x 3\n",
        "            LBBlock(128, 128),\n",
        "            LBBlock(128, 128),\n",
        "            LBBlock(128, 128)\n",
        "        )\n",
        "\n",
        "        # First DLBBlock: [128, 192, 192] -> 14x14 feature map\n",
        "        self.dlb1 = nn.Sequential(\n",
        "            DLBBlock(128, 192),\n",
        "            DLBBlock(192, 192),\n",
        "            DLBBlock(192, 192)\n",
        "        )\n",
        "\n",
        "        # Second DLBBlock: [192, 256, 256] -> 7x7 feature map\n",
        "        self.dlb2 = nn.Sequential(\n",
        "            DLBBlock(192, 256),\n",
        "            DLBBlock(256, 256),\n",
        "            DLBBlock(256, 512)\n",
        "        )\n",
        "\n",
        "        # Global average pooling (7x7 feature map to 1x1)\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(512, 10)  # For CIFAR-10, which has 10 classes\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        #print(x.shape)\n",
        "        x = self.initial_conv(x)                  # Initial 3x3 convolution with stride 2, 112^2\n",
        "        #print(x.shape)\n",
        "        x = self.pool(x)                           # First pooling layer, 56^2\n",
        "        #print(x.shape)\n",
        "        x = self.lb1(x)                            # First set of LB blocks, 56^2\n",
        "        x = self.pool(x)                           # Pooling to reduce to 28x28\n",
        "        #print(x.shape)\n",
        "        x = self.lb2(x)                            # Second set of LB blocks\n",
        "        x = self.pool(x)                           # Pooling to reduce to 14x14\n",
        "        #print(x.shape)\n",
        "        x = self.dlb1(x)                           # First set of DLB blocks\n",
        "        x = self.pool(x)                           # Pooling to reduce to 7x7\n",
        "        #print(x.shape)\n",
        "        x = self.dlb2(x)                           # Second set of DLB blocks\n",
        "        x = self.global_avg_pool(x)                # Global average pooling to get 1x1 feature map\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 512)                        # Flatten for the fully connected layer\n",
        "        x = self.fc(x)                             # Fully connected layer\n",
        "        x = self.dequant(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Xq6EttlRTzsT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_list = [\n",
        "    ['depthwise1', 'bn1'],  # Conv + BN\n",
        "    ['pointwise', 'bn2', 'relu1'],  # Conv + BN + ReLU\n",
        "    ['depthwise2', 'bn3', 'relu2']  # Conv + BN + ReLU\n",
        "]\n",
        "\n",
        "def fuse_model(model):\n",
        "    for module_name, module in model.named_children():\n",
        "        if isinstance(module, (LBBlock, DLBBlock)):\n",
        "            fusion_list = [\n",
        "                ['depthwise1', 'bn1'],\n",
        "                ['pointwise', 'bn2', 'relu1'],\n",
        "                ['depthwise2', 'bn3', 'relu2']\n",
        "            ]\n",
        "            torch.quantization.fuse_modules(module, fusion_list, inplace=True)\n",
        "        else:\n",
        "            # Recursively apply to child modules\n",
        "            fuse_model(module)"
      ],
      "metadata": {
        "id": "JzEFh0w-Cbj5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fp32 = EtinyNet()\n",
        "model_fp32.load_state_dict(torch.load('/content/drive/My Drive/ECE570/Project/EtinyNetDict.pth'))\n",
        "model_fp32.eval()\n",
        "\n",
        "fuse_model(model_fp32)\n",
        "\n",
        "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "model_int8 = model_fp32\n",
        "model_int8.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "model_int8_prepared = torch.quantization.prepare(model_int8)\n",
        "print(model_int8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sOM3l95uTXh8",
        "outputId": "986d2150-ee78-423a-b1e9-91efb586423d",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2a40f749895f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_fp32.load_state_dict(torch.load('/content/drive/My Drive/ECE570/Project/EtinyNetDict.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EtinyNet(\n",
            "  (initial_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (lb1): Sequential(\n",
            "    (0): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (1): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (2): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (3): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (lb2): Sequential(\n",
            "    (0): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (1): LBBlock(\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (2): LBBlock(\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (3): LBBlock(\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (dlb1): Sequential(\n",
            "    (0): DLBBlock(\n",
            "      (match_channels): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): DLBBlock(\n",
            "      (depthwise1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): DLBBlock(\n",
            "      (depthwise1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dlb2): Sequential(\n",
            "    (0): DLBBlock(\n",
            "      (match_channels): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (depthwise1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): DLBBlock(\n",
            "      (depthwise1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): DLBBlock(\n",
            "      (match_channels): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (depthwise1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (quant): QuantStub()\n",
            "  (dequant): DeQuantStub()\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Calibration Data through Model\n",
        "# Use a no_grad context to avoid any training interference\n",
        "with torch.no_grad():\n",
        "    for images, _ in calibration_loader:\n",
        "      model_int8_prepared(images)  # This step runs the calibration data through the model"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D4ZtiFnE2zWZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_int8_converted = torch.quantization.convert(model_int8_prepared)\n",
        "print(model_int8_converted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "Ly2U3BuL3w3a",
        "outputId": "6f0e0a0d-dfad-4ffb-ca7f-3ec7f87bf8e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EtinyNet(\n",
            "  (initial_conv): QuantizedConv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.1268494427204132, zero_point=64, padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (lb1): Sequential(\n",
            "    (0): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.13847623765468597, zero_point=64, padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(32, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.057288192212581635, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.09686513990163803, zero_point=0, padding=(1, 1), groups=32)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (1): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.2063780426979065, zero_point=69, padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(32, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.06043253839015961, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.09248457103967667, zero_point=0, padding=(1, 1), groups=32)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (2): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.19650200009346008, zero_point=64, padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(32, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.06827086210250854, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.1010056585073471, zero_point=0, padding=(1, 1), groups=32)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (3): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.18063127994537354, zero_point=69, padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(32, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.08019743859767914, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.05716894939541817, zero_point=0, padding=(1, 1), groups=32)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (lb2): Sequential(\n",
            "    (0): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.12954910099506378, zero_point=62, padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(32, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.05511007457971573, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.06558462232351303, zero_point=0, padding=(1, 1), groups=128)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (1): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.14539498090744019, zero_point=60, padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.05248744785785675, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07119815051555634, zero_point=0, padding=(1, 1), groups=128)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (2): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.15251033008098602, zero_point=66, padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.05526386946439743, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07485884428024292, zero_point=0, padding=(1, 1), groups=128)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (3): LBBlock(\n",
            "      (depthwise1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1641727089881897, zero_point=69, padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.059328343719244, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.008562237955629826, zero_point=0, padding=(1, 1), groups=128)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (dlb1): Sequential(\n",
            "    (0): DLBBlock(\n",
            "      (match_channels): QuantizedConv2d(128, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.018359605222940445, zero_point=122)\n",
            "      (depthwise1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.13463637232780457, zero_point=62, padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(128, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.023550236597657204, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.02712997980415821, zero_point=0, padding=(1, 1), groups=192)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): QFunctional(\n",
            "        scale=0.042940620332956314, zero_point=81\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): DLBBlock(\n",
            "      (depthwise1): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.09976080805063248, zero_point=64, padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(192, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.0274264607578516, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.03985251486301422, zero_point=0, padding=(1, 1), groups=192)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): QFunctional(\n",
            "        scale=0.06338638812303543, zero_point=73\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): DLBBlock(\n",
            "      (depthwise1): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.10468089580535889, zero_point=63, padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(192, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.034915607422590256, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.04673360660672188, zero_point=0, padding=(1, 1), groups=192)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): QFunctional(\n",
            "        scale=0.12678693234920502, zero_point=61\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dlb2): Sequential(\n",
            "    (0): DLBBlock(\n",
            "      (match_channels): QuantizedConv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.08814658224582672, zero_point=71)\n",
            "      (depthwise1): QuantizedConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.14741098880767822, zero_point=63, padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(192, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.0711182951927185, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.07950622588396072, zero_point=0, padding=(1, 1), groups=256)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): QFunctional(\n",
            "        scale=0.21777817606925964, zero_point=48\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): DLBBlock(\n",
            "      (depthwise1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.15920156240463257, zero_point=61, padding=(1, 1), groups=256)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(256, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.07816138118505478, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.09587328881025314, zero_point=0, padding=(1, 1), groups=256)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): QFunctional(\n",
            "        scale=0.49865323305130005, zero_point=40\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): DLBBlock(\n",
            "      (match_channels): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.5422150492668152, zero_point=67)\n",
            "      (depthwise1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.14822444319725037, zero_point=61, padding=(1, 1), groups=256)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): QuantizedConvReLU2d(256, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.12706534564495087, zero_point=0)\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.11093895882368088, zero_point=0, padding=(1, 1), groups=512)\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): QFunctional(\n",
            "        scale=1.0134602785110474, zero_point=57\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.5413879156112671, zero_point=42, qscheme=torch.per_channel_affine)\n",
            "  (quant): Quantize(scale=tensor([0.0324]), zero_point=tensor([61]), dtype=torch.quint8)\n",
            "  (dequant): DeQuantize()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model_int8_converted(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D5q01UDtUn_R",
        "outputId": "76974f9e-fd27-4ec2-aace-71a3234c5910",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 86.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.quantization.observer import HistogramObserver\n",
        "from torch.quantization.observer import PerChannelMinMaxObserver\n",
        "from torch.quantization import QConfig"
      ],
      "metadata": {
        "id": "SeoeMfgyEkKC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationObserver4bit(HistogramObserver):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.quant_min = 0\n",
        "        self.quant_max = 2 ** 4 - 1  # 0 to 15 for 4 bits\n",
        "        self.dtype = torch.quint8\n",
        "\n",
        "class WeightObserver4bit(PerChannelMinMaxObserver):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.quant_min = -2 ** (4 - 1)  # -8\n",
        "        self.quant_max = 2 ** (4 - 1) - 1  # 7\n",
        "        self.dtype = torch.qint8\n",
        "        self.qscheme = torch.per_channel_symmetric\n",
        "\n",
        "custom_qconfig_4bit = QConfig(\n",
        "    activation=ActivationObserver4bit.with_args(reduce_range=False),\n",
        "    weight=WeightObserver4bit.with_args(reduce_range=False)\n",
        ")"
      ],
      "metadata": {
        "id": "aKlVMIK5En3Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fp32 = EtinyNet()\n",
        "model_fp32.load_state_dict(torch.load('/content/drive/My Drive/ECE570/Project/EtinyNetDict.pth'))\n",
        "model_fp32.eval()\n",
        "\n",
        "fuse_model(model_fp32)\n",
        "\n",
        "model_fp32.qconfig = custom_qconfig_4bit\n",
        "model_int4 = model_fp32\n",
        "model_int4.qconfig = model_int4.qconfig = custom_qconfig_4bit\n",
        "model_int4_prepared = torch.quantization.prepare(model_int4)\n",
        "print(model_int4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7tNervSkEyJl",
        "outputId": "71c6f0f5-66cd-467a-db7e-9d4f71583975"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EtinyNet(\n",
            "  (initial_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (lb1): Sequential(\n",
            "    (0): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (1): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (2): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (3): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (lb2): Sequential(\n",
            "    (0): LBBlock(\n",
            "      (depthwise1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (1): LBBlock(\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (2): LBBlock(\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "    (3): LBBlock(\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "    )\n",
            "  )\n",
            "  (dlb1): Sequential(\n",
            "    (0): DLBBlock(\n",
            "      (match_channels): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (depthwise1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): DLBBlock(\n",
            "      (depthwise1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): DLBBlock(\n",
            "      (depthwise1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dlb2): Sequential(\n",
            "    (0): DLBBlock(\n",
            "      (match_channels): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (depthwise1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): DLBBlock(\n",
            "      (depthwise1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): DLBBlock(\n",
            "      (match_channels): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (depthwise1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "      (bn1): Identity()\n",
            "      (pointwise): ConvReLU2d(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn2): Identity()\n",
            "      (depthwise2): ConvReLU2d(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bn3): Identity()\n",
            "      (relu1): Identity()\n",
            "      (relu2): Identity()\n",
            "      (add): FloatFunctional(\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (quant): QuantStub()\n",
            "  (dequant): DeQuantStub()\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-64d8c826fd5d>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_fp32.load_state_dict(torch.load('/content/drive/My Drive/ECE570/Project/EtinyNetDict.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Calibration Data through Model\n",
        "# Use a no_grad context to avoid any training interference\n",
        "with torch.no_grad():\n",
        "    for images, _ in calibration_loader:\n",
        "      model_int4_prepared(images)  # This step runs the calibration data through the model\n",
        "model_int4_converted = torch.quantization.convert(model_int4_prepared)"
      ],
      "metadata": {
        "id": "grxiVpTPFOK5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model_int4_converted(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TzmjdIJUFSSM",
        "outputId": "0898ff4b-452b-453f-d362-71a70d6b8793"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 22.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_int4_converted, '/content/drive/My Drive/ECE570/Project/modei_int4.pth')\n",
        "torch.save(model_int4_converted.state_dict(), '/content/drive/My Drive/ECE570/Project/model_int4_Dict.pth')\n",
        "torch.save(model_int8_converted, '/content/drive/My Drive/ECE570/Project/modei_int8.pth')\n",
        "torch.save(model_int8_converted.state_dict(), '/content/drive/My Drive/ECE570/Project/model_int8_Dict.pth')"
      ],
      "metadata": {
        "id": "2HwhfQXzG-vC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_quantized_model_size(model):\n",
        "    \"\"\"\n",
        "    Calculate the size of a quantized model using its state_dict.\n",
        "    \"\"\"\n",
        "    state_dict = model.state_dict()\n",
        "\n",
        "    # Check if state_dict is empty\n",
        "    if not state_dict:\n",
        "        print(\"Warning: State dictionary is empty!\")\n",
        "        return\n",
        "\n",
        "    # Calculate total size in bytes\n",
        "    total_size = 0\n",
        "    total_params = 0\n",
        "\n",
        "    print(\"Model Parameters and Buffers:\")\n",
        "    for name, tensor in state_dict.items():\n",
        "        # Check if the item is a tensor\n",
        "        if isinstance(tensor, torch.Tensor):\n",
        "            num_elements = tensor.numel()\n",
        "            element_size = tensor.element_size()\n",
        "            size_in_kb = (num_elements * element_size) / 1024\n",
        "            total_size += num_elements * element_size\n",
        "            total_params += num_elements\n",
        "\n",
        "\n",
        "    # Convert total size to megabytes\n",
        "    size_in_mb = total_size / (1024 ** 2)\n",
        "    print(f\"\\nTotal Quantized Model size: {size_in_mb:.2f} MB\")\n",
        "    print(f\"Total number of parameters: {total_params}\")\n",
        "\n",
        "# Example usage\n",
        "get_quantized_model_size(model_int4_converted)\n",
        "get_quantized_model_size(model_int8_converted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DxMTcvGPB0Wy",
        "outputId": "a41da12e-3cc8-4ab1-ffca-0bff19aeec9c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Parameters and Buffers:\n",
            "\n",
            "Total Quantized Model size: 0.64 MB\n",
            "Total number of parameters: 650412\n",
            "Model Parameters and Buffers:\n",
            "\n",
            "Total Quantized Model size: 0.64 MB\n",
            "Total number of parameters: 650412\n"
          ]
        }
      ]
    }
  ]
}